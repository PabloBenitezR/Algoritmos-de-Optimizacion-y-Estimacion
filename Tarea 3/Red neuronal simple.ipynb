{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función sigmoide logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def d_sigmoide(z):\n",
    "    return d_sigmoide(z) * (1 - d_sigmoide(z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estructura de la red neuronal, con una entrada \"x\", y una salida \"y\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función sigmoide logística es una función matemática que se utiliza comúnmente en redes neuronales y regresión logística. Se define como:\n",
    "\n",
    "\\[ \\sigma(z) = \\frac{1}{1 + e^{-z}} \\]\n",
    "\n",
    "La derivada de la función sigmoide es:\n",
    "\n",
    "\\[ \\sigma'(z) = \\sigma(z) \\cdot (1 - \\sigma(z)) \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(self, y_real, y_pred):\n",
    "        return 0.5 * (y_real - y_pred) ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, x, y_real):\n",
    "        # Error\n",
    "        error = self.y_hat - y_real\n",
    "\n",
    "        # Gradientes de la capa de salida\n",
    "        d_w_out1 = error * self.a2\n",
    "        d_w_out2 = error * self.a4\n",
    "        d_b_out = error\n",
    "\n",
    "        # Gradientes de la capa oculta\n",
    "        d_a2 = error * self.w_out1\n",
    "        d_a4 = error * self.w_out2\n",
    "\n",
    "        d_z2 = d_a2 * d_sigmoide(self.z2)\n",
    "        d_z4 = d_a4 * d_sigmoide(self.z4)\n",
    "\n",
    "        d_w2 = d_z2 * x\n",
    "        d_w4 = d_z4 * x\n",
    "\n",
    "        d_b2 = d_z2\n",
    "        d_b4 = d_z4\n",
    "\n",
    "        # Actualización de los pesos\n",
    "        self.w_out1 -= self.learning_rate * d_w_out1\n",
    "        self.w_out2 -= self.learning_rate * d_w_out2\n",
    "        self.b_out -= self.learning_rate * d_b_out\n",
    "\n",
    "        self.w2 -= self.learning_rate * d_w2\n",
    "        self.w4 -= self.learning_rate * d_w4\n",
    "        self.b2 -= self.learning_rate * d_b2\n",
    "        self.b4 -= self.learning_rate * d_b4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, X, Y, epochs=1000):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for x, y_real in zip(X, Y):\n",
    "                # Forward\n",
    "                y_pred = self.forward(x)\n",
    "                total_loss += self.loss(y_real, y_pred)\n",
    "\n",
    "                # Backpropagation\n",
    "                self.backward(x, y_real)\n",
    "\n",
    "            # Mostrar la pérdida cada 100 épocas\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Época {epoch}, Pérdida: {total_loss / len(X)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NeuralNetwork' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Entrenar la red\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m(X, Y, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Prueba con un nuevo valor\u001b[39;00m\n\u001b[0;32m     12\u001b[0m test_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.35\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NeuralNetwork' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "# Datos de entrada (Ejemplo)\n",
    "X = np.array([0.1, 0.2, 0.3, 0.4, 0.5])  # Entrada normalizada\n",
    "Y = np.array([0.2, 0.25, 0.35, 0.40, 0.50])  # Salidas esperadas\n",
    "\n",
    "# Inicializar la red neuronal\n",
    "nn = NeuralNetwork(learning_rate=0.1)\n",
    "\n",
    "# Entrenar la red\n",
    "nn.train(X, Y, epochs=1000)\n",
    "\n",
    "# Prueba con un nuevo valor\n",
    "test_value = 0.35\n",
    "prediction = nn.forward(test_value)\n",
    "print(f\"Predicción para {test_value}: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
